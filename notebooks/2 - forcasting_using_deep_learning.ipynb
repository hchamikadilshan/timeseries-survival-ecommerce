{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2cdfcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7056dfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"../datasets/dataset.xlsx\",dtype={'CustomerID': str},parse_dates=['InvoiceDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "827db872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(541909, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd94227",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c89b347",
   "metadata": {},
   "source": [
    "## Making `Sale` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3888c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Sale\"] = (data['Quantity'] * data['UnitPrice']).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163f9d0a",
   "metadata": {},
   "source": [
    "## Dropping Unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91d5bd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"Description\",\"UnitPrice\",\"Quantity\",\"CustomerID\",\"InvoiceNo\",\"Country\",\"StockCode\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81f920b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hcham\\anaconda3\\Lib\\site-packages\\numpy\\_typing\\_scalars.py:12: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  _BoolLike_co = Union[bool, np.bool]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hcham\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\hcham\\AppData\\Local\\Temp\\ipykernel_27780\\2544866835.py\", line 3, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\hcham\\anaconda3\\Lib\\site-packages\\tensorflow\\__init__.py\", line 49, in <module>\n",
      "    from tensorflow._api.v2 import __internal__\n",
      "  File \"C:\\Users\\hcham\\anaconda3\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.__internal__ import autograph\n",
      "  File \"C:\\Users\\hcham\\anaconda3\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\autograph\\__init__.py\", line 8, in <module>\n",
      "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hcham\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\core\\ag_ctx.py\", line 21, in <module>\n",
      "    from tensorflow.python.autograph.utils import ag_logging\n",
      "  File \"C:\\Users\\hcham\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\utils\\__init__.py\", line 17, in <module>\n",
      "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
      "  File \"C:\\Users\\hcham\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\utils\\context_managers.py\", line 19, in <module>\n",
      "    from tensorflow.python.framework import ops\n",
      "  File \"C:\\Users\\hcham\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 30, in <module>\n",
      "    from numpy import typing as npt\n",
      "  File \"C:\\Users\\hcham\\anaconda3\\Lib\\site-packages\\numpy\\typing\\__init__.py\", line 158, in <module>\n",
      "    from numpy._typing import (\n",
      "  File \"C:\\Users\\hcham\\anaconda3\\Lib\\site-packages\\numpy\\_typing\\__init__.py\", line 151, in <module>\n",
      "    from ._scalars import (\n",
      "  File \"C:\\Users\\hcham\\anaconda3\\Lib\\site-packages\\numpy\\_typing\\_scalars.py\", line 12, in <module>\n",
      "    _BoolLike_co = Union[bool, np.bool]\n",
      "                               ^^^^^^^\n",
      "  File \"C:\\Users\\hcham\\anaconda3\\Lib\\site-packages\\numpy\\__init__.py\", line 305, in __getattr__\n",
      "AttributeError: module 'numpy' has no attribute 'bool'.\n",
      "`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
      "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hcham\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 2057, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hcham\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1288, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hcham\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1177, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hcham\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1030, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hcham\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 960, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hcham\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 870, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hcham\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 704, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hcham\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hcham\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hcham\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hcham\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hcham\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hcham\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"C:\\Users\\hcham\\AppData\\Roaming\\Python\\Python311\\site-packages\\executing\\executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ensure datetime index and set daily frequency\n",
    "data_daily_sales.index = pd.to_datetime(data_daily_sales.index)\n",
    "data_daily_sales = data_daily_sales.asfreq('D')\n",
    "\n",
    "# Normalize sales data (Min-Max Scaling)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_scaled = scaler.fit_transform(data_daily_sales[['Sale']])\n",
    "\n",
    "# Function to create input-output sequences\n",
    "def create_sequences(data, time_steps=7):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        X.append(data[i: i + time_steps])\n",
    "        y.append(data[i + time_steps])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Define time steps (how many past days to consider)\n",
    "time_steps = 7  # Using past 7 days to predict the next day\n",
    "\n",
    "# Create sequences\n",
    "X, y = create_sequences(data_scaled, time_steps)\n",
    "\n",
    "# Split data into train & test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Reshape input for LSTM (samples, time_steps, features)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(50, activation='relu', return_sequences=True, input_shape=(time_steps, 1)),\n",
    "    LSTM(50, activation='relu'),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(1)  # Output layer\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Predict next 100 days\n",
    "def forecast_future(model, data, num_days=100):\n",
    "    future_preds = []\n",
    "    last_sequence = data[-time_steps:].reshape(1, time_steps, 1)  # Get last available sequence\n",
    "\n",
    "    for _ in range(num_days):\n",
    "        pred = model.predict(last_sequence)[0][0]  # Predict next step\n",
    "        future_preds.append(pred)\n",
    "\n",
    "        # Update sequence with new prediction\n",
    "        last_sequence = np.roll(last_sequence, -1)\n",
    "        last_sequence[0, -1, 0] = pred  # Replace last value with predicted one\n",
    "\n",
    "    # Convert predictions back to original scale\n",
    "    future_preds = scaler.inverse_transform(np.array(future_preds).reshape(-1, 1))\n",
    "    \n",
    "    # Create date index for predictions\n",
    "    start_date = data_daily_sales.index.max() + pd.Timedelta(days=1)\n",
    "    date_range = pd.date_range(start=start_date, periods=num_days, freq='D')\n",
    "\n",
    "    return pd.DataFrame(future_preds, index=date_range, columns=['Predicted Sales'])\n",
    "\n",
    "# Get predictions\n",
    "future_sales = forecast_future(model, data_scaled, num_days=100)\n",
    "print(future_sales.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f695ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
